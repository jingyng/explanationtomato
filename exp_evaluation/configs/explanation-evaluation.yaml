{
    "port": 80,

    "server_name": "potato annotator",

    "annotation_task_name": "Explanation Evaluation",

    # Potato will write the annotation file for all annotations to this
    # directory, as well as per-annotator output files and state information
    # necessary to restart annotation.
    "output_annotation_dir": "annotation_output/",

    # The output format for the all-annotator data. Allowed formats are:
    # * jsonl
    # * json (same output as jsonl)
    # * csv
    # * tsv
    #
    "output_annotation_format": "tsv", 

    # If annotators are using a codebook, this will be linked at the top to the
    # instance for easy access
    "annotation_codebook_url": "",

    "data_files": [
       "data_files/test_examples.json"
    ],

    "item_properties": {
        "id_key": "id",
        "text_key": "text",
    },


    "user_config": {

      "allow_all_users": True,
      
      "users": [  ],
    },

    #defining the ways annotators entering the annotation system
    "login": {
      "type": 'url_direct',    #can be 'password' or 'url_direct'
      "url_argument": 'PROLIFIC_PID' # when the login type is set to 'url_direct', 'url_argument' must be setup for a direct url argument login
    },

    #the jumping-to-id function will be disabled if "jumping_to_id_disabled" is True
    "jumping_to_id_disabled": True,

    #the navigation bar will be hidden to the annotators if "hide_navbar" is True
    "hide_navbar": True,

    # define the surveyflow of the system, set up the pages before and after the data annotation page
    "surveyflow": {
      "on": True,
      "order" : ['pre_annotation','post_annotation'], # 'prestudy_passed', 'prestudy_failed', 
      "pre_annotation": ['surveyflow/instruction.jsonl', 'surveyflow/examples.jsonl', 'surveyflow/consent.jsonl'],
      "post_annotation": ['surveyflow/end.jsonl'],
      # If set, we will automatically generate testing questions similar to the annotation instances, but explicitly ask the annotator to choose one option
      "testing": ['surveyflow/testing.jsonl'],
    },

    #prestudy test, annotators who fail this test will be disalloed to continue annotation
    "prestudy": {
        "on": False,
        "minimum_score": 0.8,
        "groundtruth_key": 'whether_agree',
        "question_key": 'relationship',
        "answer_mapping": {'Yes': "Yes", 'No': "No"},
        "pass_page": 'surveyflow/prestudy_pass.jsonl',
        "fail_page": 'surveyflow/prestudy_fail.jsonl'
    },

    "automatic_assignment": {
      #whether do automatic task assignment for annotators, default False.
      "on": True,
      "output_filename": 'task_assignment.json',
      "sampling_strategy": 'ordered',
      "labels_per_instance": 10,
      "instance_per_annotator": 10,
      "test_question_per_annotator": 1, # you must set up the test question in surveyflow to use this function

      "users": [  ],
    },
    # How many seconds do you want the annotators spend on each instance, after
    # that, an alert will be sent per alert_time_each_instance seconds.
    "alert_time_each_instance": 10000000,

    "annotation_schemes": [      
        # {
        #     "annotation_type": "radio",
        #     "name": "relationship",
        #     "description": "Do you agree with the given Relationship between the Hypothesis and Premise?",
        #     "labels": [
        #        "Yes", "No",
        #     ],
        #     "sequential_key_binding": True,                        
        # },       
        {
            "annotation_type": "likert",
            "name": "Does the explanation justify the answer?",
            "description": "Given the Hypothesis and Premise, does the Explanation justify the given Relationship?",
            "labels": [
                {
                  "name": "Yes",
                  "key_value": '1'
                },

                { "name": "Weakly Yes",
                  "key_value": '2'
                },

                { "name": "Weakly No",
                  "key_value": '3'
                },
                { "name": "No",
                  "key_value": '4'
                }
            ],

            "displaying_score": False,

            # adding requirements for labels, when "required" is True, the annotators will be asked to finish the current instance to proceed
            "label_requirement": {"required":True},

            # If true, numbers [1-len(labels)] will be bound to each
            # label. Aannotations with more than 10 are not supported with this
            # simple keybinding and will need to use the full item specification
            # to bind all labels to keys.
            "sequential_key_binding": True,
        },
      {
            "annotation_type": "multiselect",
            "name": "reason",
            "description": "What are the shortcomings of the Explanation? (you can select 1 or more options)",
            "labels": [
               "Does not make sense", "Insufficient justification", "Irrelevant to the task", "Too trivial (only repeating one of the sentences)", "Contain hallucinated content (not present the premise)", "None (only if the previous answer is Yes)",
            ],

            # If true, numbers [1-len(labels)] will be bound to each
            # label. Aannotations with more than 10 are not supported with this
            # simple keybinding and will need to use the full item specification
            # to bind all labels to keys.
            "sequential_key_binding": True,    
#             # If true, the field will have an optional text box the user can
#             'has_free_response': {
#                "instruction": 'other (optional):',
#             },
        },   
    ],
    # The html that changes the visualiztation for your task. Change this file
    # to influence the layout and description of your task. This is not a full
    # HTML page, just the piece that does lays out your task's pieces
    # you may use templates in our lib, if you want to use your own template,
    # please replace the string as a path to the template
    "html_layout": "default",

    # The core UI files for Potato. You should not need to change these normally.
    #
    # Exceptions to this might include:
    # 1) You want to add custom CSS/fonts to style your task
    # 2) Your layout requires additional JS/assets to render
    # 3) You want to support additional keybinding magic
    #
    # if you want to use your own template,
    # please replace the string as a path to the template
    "base_html_template": "default",
    "header_file": "default",

    # This is where the actual HTML files will be generated
    "site_dir": "default"

}


